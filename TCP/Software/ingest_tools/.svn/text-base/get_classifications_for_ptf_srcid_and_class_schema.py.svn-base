#!/usr/bin/env python 
"""
   v0.1 Given a srcid and class schema, get the classification probabilities.

   Only PTF epochs are used in source.

   Skips spatial query for new epochs to add to source.
   Skips querying non-PTF epoch tables.

   Does generate features for the source.  Internally forms xml_string.

##### NOTE:

CREATE TABLE one_src_model_class_probs (schema_id SMALLINT UNSIGNED,
                                        schema_comment VARCHAR(80) DEFAULT '', 
			                class_id SMALLINT UNSIGNED, 
                                        class_name VARCHAR(100) DEFAULT '', 
			                prob FLOAT DEFAULT 1.0,
		                        src_id INT UNSIGNED,
			                class_rank TINYINT DEFAULT 0,
                                        prob_weight FLOAT DEFAULT 1.0,
			                gen_dtime DATETIME,
			                PRIMARY KEY(schema_comment, src_id, class_rank),
                                        INDEX(gen_dtime),
                                        INDEX(prob));
"""

import os, sys
import classification_interface
import plugin_classifier
import ptf_master
import MySQLdb


class GetClassificationsForPtfSrcid:
    """ Main class for get_classifications_for_ptf_srcid_and_class_schema.py
    """
    def __init__(self, schema_str=""):
        self.DiffObjSourcePopulator = ptf_master.Diff_Obj_Source_Populator(use_postgre_ptf=True)
        self.db = MySQLdb.connect(host=self.DiffObjSourcePopulator.xrsio.pars['rdb_host_ip_2'],
                             user=self.DiffObjSourcePopulator.xrsio.pars['rdb_user'],
                             db=self.DiffObjSourcePopulator.xrsio.pars['rdb_name_2'],
                             port=self.DiffObjSourcePopulator.xrsio.pars['rdb_port_2'])
        self.cursor = self.db.cursor()
        self.schema_str = schema_str
        self.class_schema_definition_dicts = self.init_class_schema(self.schema_str)


    def init_class_schema(self, schema_str):
        """ Initialize objects, structures for a classification schema.
        """
        class_schema_definition_dicts = {}
        class_schema_definition_dicts['mlens3 MicroLens'] = \
             self.DiffObjSourcePopulator.xrsio.pars['class_schema_definition_dicts']['mlens3 MicroLens']
        class_schema_definition_dicts['Dovi SN'] = \
             self.DiffObjSourcePopulator.xrsio.pars['class_schema_definition_dicts']['Dovi SN']
        class_schema_definition_dicts['General'] = \
             self.DiffObjSourcePopulator.xrsio.pars['class_schema_definition_dicts']['General']
        ### NOTE: schema_id == 3 is a default, unused index
        class_schema_definition_dicts[schema_str] = { \
                'schema_id':3, # For Weka, this can be found/generated by code
                'general_class_weight':1.0,
                'specific_class_weight_dict':{},
                'weka_training_model_fpath':os.path.expandvars(\
                      '$HOME/scratch/Noisification/%s/%s.model' % (schema_str, schema_str)),
                'weka_training_arff_fpath':os.path.expandvars(\
                      '$HOME/scratch/Noisification/%s/noisified_for_training.arff' % (schema_str)),
                'schema_comment':schema_str,
                'predicts_multiple_classes':True,
            }
        class_interface = classification_interface.ClassificationHandler(\
                                                      self.DiffObjSourcePopulator.xrsio.pars, \
                                                      db=self.DiffObjSourcePopulator.srcdbt.db, \
                                                      class_schema_definition_dicts=class_schema_definition_dicts)

        (classname_colnum_dict, features_list, classes_arff_str) = \
                                             class_interface.get_classdict_featureslist_from_arff(\
                                                  class_schema_definition_dicts[schema_str]['weka_training_arff_fpath'])

        self.PlugClass = plugin_classifier.PluginClassifier( \
                            class_schema_definition_dicts=class_schema_definition_dicts,\
                            class_abrv_lookup={}, \
                            use_weka_jvm=True, \
                            training_arff_features_list=[]) # ???? features_list)

        return class_schema_definition_dicts


    def insert_classif_results_to_rdb(self, class_probs_list=[], src_id=0, schema_str=""):
        """ INSERT classification results for schema & src_id to
        to analysis TABLE in RDB.
        """
        #db = MySQLdb.connect(host=self.DiffObjSourcePopulator.xrsio.pars['rdb_host_ip_2'],
        #                     user=self.DiffObjSourcePopulator.xrsio.pars['rdb_user'],
        #                     db=self.DiffObjSourcePopulator.xrsio.pars['rdb_name_2'],
        #                     port=self.DiffObjSourcePopulator.xrsio.pars['rdb_port_2'])
        #cursor = db.cursor()
        
        insert_list = ['INSERT INTO source_test_db.one_src_model_class_probs (schema_id, schema_comment, class_id, class_name, prob, src_id, class_rank, gen_dtime) VALUES ']

        skip_schema_ids = [0,1,2] # microlens, dovi, general
        for class_dict in class_probs_list:
            if class_dict['schema_id'] not in skip_schema_ids:
                insert_list.append('(%d, "%s", %d, "%s", %lf, %d, %d, NOW()), ' % \
                                   (class_dict['schema_id'],
                                    schema_str,
                                    class_dict['class_id'],
                                    class_dict['class_name'],
                                    class_dict['prob'],
                                    src_id,
                                    class_dict['class_rank']))
        if len(insert_list) > 1:
            self.cursor.execute(''.join(insert_list)[:-2] + " ON DUPLICATE KEY UPDATE class_id=VALUES(class_id), class_name=VALUES(class_name), prob=VALUES(prob), gen_dtime=VALUES(gen_dtime)")
        #cursor.close()
        #db.close()



    def retrieve_ptf_variable_sources(self):
        """ Retrieve the associated srcids of ptfxxx sources which are marked VarStar.
        """
        #db = MySQLdb.connect(host=self.DiffObjSourcePopulator.xrsio.pars['rdb_host_ip_2'],
        #                     user=self.DiffObjSourcePopulator.xrsio.pars['rdb_user'],
        #                     db=self.DiffObjSourcePopulator.xrsio.pars['rdb_name_2'],
        #                     port=self.DiffObjSourcePopulator.xrsio.pars['rdb_port_2'])
        #cursor = db.cursor()

        select_str = 'SELECT tcp_source_id FROM source_test_db.caltech_classif_summary WHERE caltech_candidate_type="VarStar"'

        self.cursor.execute(select_str)
        results = self.cursor.fetchall()
        out_list = []
        for result in results:
            out_list.append(int(result[0]))

        #cursor.close()
        #db.close()
        return out_list


    def check_srcid_ingested(self, src_id, schema_str):
        """ Retrieve the associated srcids of ptfxxx sources which are marked VarStar.
        """
        select_str = 'SELECT src_id FROM source_test_db.one_src_model_class_probs WHERE src_id=%d AND schema_comment="%s"' % (src_id, schema_str)

        self.cursor.execute(select_str)
        results = self.cursor.fetchall()
        for result in results:
            if result[0] == src_id:
                return True

        return False # no match



    def main(self, src_id=0):
        """ Main for GetClassificationsForPtfSrcid
        """
        srcid_xml_tuple_list = self.DiffObjSourcePopulator.xrsio.get_vosourcelist_for_ptf_using_srcid(src_id)

        (class_probs_dict, plugin_classification_dict) = \
                           self.PlugClass.do_classification(srcid_xml_tuple_list, \
                                          class_schema_definition_dicts=self.class_schema_definition_dicts, \
                                          do_logging=False)

        #import pdb; pdb.set_trace()

        #import pprint
        #pprint.pprint(class_probs_dict)

        self.insert_classif_results_to_rdb(class_probs_list=class_probs_dict[src_id],
                                           src_id=src_id, schema_str=self.schema_str)


class Ipython_Task_Controller:
    """ This class deals with initializing, spawning, controlling the ipython tasks
    """
    def __init__(self, schema_str=""):
        """
        """
        self.schema_str = schema_str


    def initialize_ipengines(self):
        """ Initialize ipengines, load environ vars, etc.
        """
        from IPython.kernel import client # 20091202 added

        self.mec = client.MultiEngineClient()
        #THE FOLLOWING LINE IS DANGEROUS WHEN OTHER TYPES OF TASKS MAY BE OCCURING:
        self.mec.reset(targets=self.mec.get_ids()) # Reset the namespaces of all engines
        self.tc = client.TaskClient()
        self.tc.clear() # This supposedly clears the list of finished task objects in the task-client
        self.mec.flush() # This doesnt seem to do much in our system.

        #import pdb; pdb.set_trace() # DEBUG
        #import os,sys
        #import classification_interface
        #import plugin_classifier
        #import ptf_master
        #import MySQLdb
        #import get_classifications_for_ptf_srcid_and_class_schema
        #Get_Classifications_For_Ptf_Srcid = get_classifications_for_ptf_srcid_and_class_schema.GetClassificationsForPtfSrcid(schema_str=self.schema_str)
            
        exec_str = """import os,sys
import classification_interface
import plugin_classifier
import ptf_master
import MySQLdb
import get_classifications_for_ptf_srcid_and_class_schema
Get_Classifications_For_Ptf_Srcid = get_classifications_for_ptf_srcid_and_class_schema.GetClassificationsForPtfSrcid(schema_str="%s")
        """  % (self.schema_str)
        self.mec.execute(exec_str)


    # OBSOLETE:
    def spawn_tasks__crap2(self):
        """ This spawns ipython ipengine tasks

        NOTE: These ipython tasks are intended to be run on a single machine (transx)
        """
        Get_Classifications_For_Ptf_Srcid = GetClassificationsForPtfSrcid(schema_str=self.schema_str) # this class is just loaded for the next simple method (really, this next method could exist elsewhere and less initialization would be needed):
        total_srcid_list = Get_Classifications_For_Ptf_Srcid.retrieve_ptf_variable_sources()

        # KLUDGE: unfortunately we need to reinitialize taskclient due to memory leaks in a primary class.
        #list_incr = 5
        #for i_low in xrange(0, len(total_srcid_list), list_incr):
        #    short_srcid_list = total_srcid_list[i_low:i_low + list_incr]
        if 1:
            short_srcid_list = total_srcid_list
            exec_str = """schema_str="%s"
import os,sys
import classification_interface
import plugin_classifier
import ptf_master
import MySQLdb
import get_classifications_for_ptf_srcid_and_class_schema
Get_Classifications_For_Ptf_Srcid = get_classifications_for_ptf_srcid_and_class_schema.GetClassificationsForPtfSrcid(schema_str=schema_str)
for src_id in srcid_list:
    try:
        is_already_ingested = Get_Classifications_For_Ptf_Srcid.check_srcid_ingested(src_id, schema_str)
        if not is_already_ingested:
            Get_Classifications_For_Ptf_Srcid.main(src_id=src_id)
    except:
        pass # skipping this srcid
del Get_Classifications_For_Ptf_Srcid""" % (self.schema_str)
            taskid = self.tc.run(client.StringTask(exec_str, \
                                                   push={'srcid_list':short_srcid_list}, \
                                                   clear_after=True))

    def spawn_tasks(self):
        """ This spawns ipython ipengine tasks

        NOTE: These ipython tasks are intended to be run on a single machine (transx)
        """
        Get_Classifications_For_Ptf_Srcid = GetClassificationsForPtfSrcid(schema_str=self.schema_str) # this class is just loaded for the next simple method (really, this next method could exist elsewhere and less initialization would be needed):
        total_srcid_list = Get_Classifications_For_Ptf_Srcid.retrieve_ptf_variable_sources()

        # KLUDGE: unfortunately we need to reinitialize taskclient due to memory leaks in a primary class.
        list_incr = 5
        for i_low in xrange(0, len(total_srcid_list), list_incr):
            short_srcid_list = total_srcid_list[i_low:i_low + list_incr]
            exec_str = """schema_str="%s"
for src_id in srcid_list:
    try:
        #is_already_ingested = Get_Classifications_For_Ptf_Srcid.check_srcid_ingested(src_id, schema_str)
        #if not is_already_ingested:
        if True:
            Get_Classifications_For_Ptf_Srcid.main(src_id=src_id)
    except:
        pass # skipping this srcid""" % (self.schema_str)
            taskid = self.tc.run(client.StringTask(exec_str, \
                                                   push={'srcid_list':short_srcid_list}))
            


    def wait_for_tasks_to_finish(self):
        """ Wait for task client / ipengine tasks to finish.
        """
        import time
	while ((self.tc.queue_status()['scheduled'] > 0) or
 	       (self.tc.queue_status()['pending'] > 0)):
            print self.tc.queue_status()
            print 'Sleep... 3 in get_classifications_for_ptf_srcid_and_class_schema.py'
            time.sleep(3)
        print 'done with while loop'


    def main(self):
        """
        Main for Ipython_Task_Controller class
        """
        self.initialize_ipengines()
        self.spawn_tasks()
        self.wait_for_tasks_to_finish()



if __name__ == '__main__':

    # I only want these modules imported when run from command line
    #   (eg: when being used as an IPython spawning / controller)
    from IPython.kernel import client
    import time

    #if len(sys.argv) > 1:
    #    src_id = int(sys.argv[2])
    #else:
    src_id = 3611089
    #schema_str = '%s_%d' % (sys.argv[1], src_id)
    #schema_str = "50nois_00epch_100need_0.050mtrc_no_period"
    schema_str = '%s' % (sys.argv[1])

    if 1:
        IpythonTaskController = Ipython_Task_Controller(schema_str=schema_str)
        IpythonTaskController.main()

    else:
        # OLD: non-ipython run:
        Get_Classifications_For_Ptf_Srcid = GetClassificationsForPtfSrcid(schema_str=schema_str)

        srcid_list = Get_Classifications_For_Ptf_Srcid.retrieve_ptf_variable_sources()
        for src_id in srcid_list:
            try:
                #is_already_ingested = Get_Classifications_For_Ptf_Srcid.check_srcid_ingested(src_id, schema_str)
                #if not is_already_ingested:
                if True:
                    Get_Classifications_For_Ptf_Srcid.main( \
                                  src_id=src_id)
            except:
                print 'skipping', src_id


