#!/bin/bash -l
#Preliminary CARVER parallel batch script for StarVars
#07/16/2012
#Chesny

#-------------------------------------------------------------
# ******TO SUBMIT BATCH SCRIPT******
#carver% qsub linear_trial.pbs
#-------------------------------------------------------------

#PBS -N linear_trial_par
#PBS -q debug

#SPECIFY NUMBER OF NODES AND JOBS RUNNING ON EACH.  GIVE MAX AMOUNT OF TIME EXPECTED
#BE CAREFUL... SOME OF THESE COMMANDS MAY NOT BE NECESSARY...
#PBS -l nodes=1:ppn=1,walltime=00:02:00
#PBS -j oe
#PBS -V

#-------------------------------------------------------------
#FOR PYTHON
#-------------------------------------------------------------

module load python/2.7.1 numpy/1.6.1 scipy/0.10.1 ipython/0.12.1 R/2.12.1 mysql/5.1.63

#-------------------------------------------------------------
#SPECIFY WORKING DIRECTORY i.e. LOCATION OF JOB FILES
#-------------------------------------------------------------

cd TCP/Software/ingest_tools/
#cd $PBS_O_WORKDIR

#python starvars_feature_generation_L.py 1
source linear_trial_bf1.txt

#-------------------------------------------------------------
#FOR RUNNING MULTIPLE PARALLEL JOBS SEQUENIALLY
#-------------------------------------------------------------

#SPECIFY ACTUAL JOB FILENAMES
#mpirun -np 128 ./my_executable1
#mpirun -np 32 ./my_executable2
#mpirun -np 64 ./my_executable3

#-------------------------------------------------------------
#FOR RUNNING MULTIPLE PARALLEL JOBS SIMULTANEOUSLY
#-------------------------------------------------------------

#SPLIT UP JOBS PER CORE
#Run 'num_jobs' jobs simultaneously, each with 'tasks_per_job' cores
#let num_jobs=1
#let tasks_per_job=3

#Assume jobs run in separate directories, job1, job2, ...
#for i in $(seq $num_jobs)
#do
# 	cd job$i

    #write hostfile for i-th job to use
#    let lstart=($i-1)*${tasks_per_job}+1
#    let lend=${lstart}+${tasks_per_job}-1
#    sed -n ${lstart},${lend}'p' < $PBS_NODEFILE >nodefile

#    module load python/2.7.1 numpy/1.6.1 scipy/0.10.1 ipython/0.12.1 R/2.12.1 mysql/5.1.63
#    mpirun -np $tasks_per_job -hostfile nodefile gpaw-python starvars_feature_generation_L.py $i >& linear_par_job$i.out &

# 	cd ..
 	
#done

#wait

#-------------------------------------------------------------
#FOR RUNNING JOBS WITH DEPENDENCIES
#-------------------------------------------------------------

#RUN JOB2 ONLY AFTER JOB1 SUCCEEDS
#carver% qsub job1.pbs
#carver% qsub -W depend=afterok:123456.cvrsvc09-ib job2.pbs

#SAME, BUT IN BATCH SCRIPTcarver% qsub job1.pbs
#carver% qsub job2.pbs
#WHERE JOB2 EQ... #PBS -W depend=afterok:123456.cvrsvc09-ib

# ******CHAINED DEPENDENCY JOBS******

#: ${job_number:="1"}           # set job_number to 1 if it is undefined
#job_number_max=3
#JOBID="${PBS_JOBID}"          
# 
#cd $PBS_O_WORKDIR
# 
#echo "hi from ${PBS_JOBID}"
# 
#if [[ ${job_number} -lt ${job_number_max} ]]
#then
#(( job_number++ ))
#next_jobid=$(qsub -v job_number=${job_number} -W depend=afterok:${JOBID} runit.pbs)
#echo "submitted ${next_jobid}"
#fi
# 
#sleep 15
#echo "${PBS_JOBID} done"
