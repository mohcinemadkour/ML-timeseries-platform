#!/usr/bin/env python
"""
This code is to explore using active learning to build a
better ASAS <-> nomad source color association classifier.

This uses output .arff from get_colors_for_tutor_sources.py when using:
        best_nomad_sources = GetColorsUsingNomad.generate_nomad_tutor_source_associations(projid=126,
        pkl_fpath=pkl_fpath,
        do_store_nomad_sources_for_classifier=True)

This arrff has the form:
@RELATION ts
@ATTRIBUTE dist NUMERIC
@ATTRIBUTE j_acvs_nomad NUMERIC
@ATTRIBUTE h_acvs_nomad NUMERIC
@ATTRIBUTE k_acvs_nomad NUMERIC
@ATTRIBUTE jk_acvs_nomad NUMERIC
@ATTRIBUTE v_tutor_nomad NUMERIC
@ATTRIBUTE class {'match','not'}
@data

"""
import sys, os
from rpy2.robjects.packages import importr
from rpy2 import robjects

# These are sources which were in the "test_withsrcid.arff" file,
#    sources which are not classified by the original hardcoded classifier
#    and I now pretend are not decided by some previous active-learning user.
#     - I also made sure there were no missing-value attributes in these lines


class Nomad_Colors_Assoc_AL:
    """ Class for doing the active learning for classifier which associates
    nomad sources to ASAS sources using color & distance based features.

    This is related to get_colors_for_tutor_source.py
    """
    def __init__(self, pars={}):
        self.pars = pars

        algorithms_dirpath = os.path.abspath(os.environ.get("TCP_DIR") + 'Algorithms/')
        sys.path.append(algorithms_dirpath)

        import rpy2_classifiers
        self.rc = rpy2_classifiers.Rpy2Classifier(algorithms_dirpath=algorithms_dirpath)



    def load_arff(self, arff_str, skip_missingval_lines=False, fill_arff_rows=False):
        """ Parse existing arff with Nomad/ASAS color based features
        """
        data_dict = self.rc.parse_full_arff(arff_str=arff_str, skip_missingval_lines=skip_missingval_lines, fill_arff_rows=fill_arff_rows)
        return data_dict



    def actlearn_randomforest(self, traindata_dict={},
                              testdata_dict={},
                              do_ignore_NA_features=False,
                              ntrees=1000, mtry=25,
                              nfolds=10, nodesize=5,
                              num_srcs_for_users=100,
                              random_seed=0,
                              both_user_match_srcid_bool=[],
                              actlearn_sources_freqsignifs=[]):
        """
        This was adapted from:

           rpy2_classifiers.py:actlearn_randomforest():
                  - Train a randomForest() R classifier : Taken from class_cv.R : rf.cv (L40)

        """
        if do_ignore_NA_features:
            print "actlearn_randomforest():: do_ignore_NA_features==True not implemented because obsolete"
            raise



        train_featname_longfeatval_dict = traindata_dict['featname_longfeatval_dict']
        for feat_name, feat_longlist in train_featname_longfeatval_dict.iteritems():
            #if feat_name == 'dist':
            #    import pdb; pdb.set_trace()
            #    print

            train_featname_longfeatval_dict[feat_name] = robjects.FloatVector(feat_longlist)
        traindata_dict['features'] = robjects.r['data.frame'](**train_featname_longfeatval_dict)
        traindata_dict['classes'] = robjects.StrVector(traindata_dict['class_list'])

        robjects.globalenv['xtr'] = traindata_dict['features']
        robjects.globalenv['ytr'] = traindata_dict['classes']
        
        test_featname_longfeatval_dict = testdata_dict['featname_longfeatval_dict']
        for feat_name, feat_longlist in test_featname_longfeatval_dict.iteritems():
            #if feat_name == 'dist':
            #    import pdb; pdb.set_trace()
            #    print
            test_featname_longfeatval_dict[feat_name] = robjects.FloatVector(feat_longlist)
        testdata_dict['features'] = robjects.r['data.frame'](**test_featname_longfeatval_dict)
        testdata_dict['classes'] = robjects.StrVector(testdata_dict['class_list'])

        robjects.globalenv['xte'] = testdata_dict['features']
        robjects.globalenv['yte'] = testdata_dict['classes']

        #import pdb; pdb.set_trace()
        #print

        #robjects.globalenv['instep'] = robjects.IntVector(actlearn_used_srcids_indicies)
        #robjects.globalenv['incl_tr'] = robjects.BoolVector(both_user_match_srcid_bool)
        robjects.globalenv['actlearn_sources_freqsignifs'] = robjects.FloatVector(actlearn_sources_freqsignifs)
        robjects.globalenv['both_user_match_srcid_bool'] = robjects.BoolVector(both_user_match_srcid_bool)

        #for class_name in testdata_dict['class_list']:
        #    if (('algol' in class_name.lower()) or ('persei' in class_name.lower())):
        #        print '!', class_name

        r_str  = '''
    cat("In R code\n")

    m=%d

    ntrees=%d
    mtry=%d
    nfolds=%d

    ytr = class.debos(ytr)

    n.tr = length(ytr) # number of training data
    n.te = dim(xte)[1] # number of test data

    if(is.null(mtry)){ mtry = ceiling(sqrt(dim(xtr)[2]))} # set mtry
    #xte.imp = missForest(xte, verbose=TRUE)$Ximp
    #xtr.imp = missForest(xtr, verbose=TRUE)$Ximp # dstarr hack to get rid of training missingvals
    rf_clfr = randomForest(x=xtr,y=ytr,xtest=xte,ntrees=ntrees,mtry=mtry,proximity=TRUE,nodesize=%d)
    rho = rf_clfr$test$proximity # RF proximity matrix, n.tr by n.te matrix

    cat("Selecting best objects\n")
    n.bar = apply(rho[1:n.te,(n.te+1):(n.te+n.tr)],1,sum) # avg. # training data in same terminal node
    p.hat = apply(rf_clfr$test$votes,1,max)
    err.decr = ((1-p.hat)/(n.bar+1)) %srho[1:n.te,1:n.te] # this is Delta V


    # choose probabalistically:
    select = sample(1:n.te,m,prob=err.decr/sum(err.decr),replace=FALSE)
    #return(list(select=select,select.pred=rf_clfr$test$predicted[select],select.predprob=rf_clfr$test$votes[select,],err.decr=err.decr,all.pred=rf_clfr$test$predicted,all.predprob=rf_clfr$test$votes))

    # # # This is just needed for filling the ASAS catalog tables:
    rf_applied_to_train = randomForest(x=xtr,y=ytr,xtest=xtr,ntrees=ntrees,mtry=mtry,proximity=TRUE,nodesize=%d)
    # # #

        ''' % (num_srcs_for_users, ntrees, mtry, nfolds, nodesize, "%*%", nodesize)


        classifier_out = robjects.r(r_str)

        #robjects.globalenv['pred_forconfmat']
        #robjects.r("rf_clfr$classes")

        possible_classes = robjects.r("rf_clfr$classes")

        actlearn_tups = []
        #  Nice and kludgey.  Could do this in R if I knew it a bit better
        #for i, srcid in enumerate(data_dict['srcid_list']):

        for i in robjects.globalenv['select']:
            # I think the robjects.globalenv['select'] R array has an index starting at i=1
            #   so this means if R array gives i=999, then this translates srcid_list[i=998]
            #   so this means if R array gives i=1, then this translates srcid_list[i=0]
            srcid = testdata_dict['srcid_list'][i-1]# index is python so starts at 0
            actlearn_tups.append((int(srcid), robjects.globalenv['err.decr'][i-1]))# I tested this, i starts at 0, 2012-03-12 dstarr confirmed


        #import pdb; pdb.set_trace()
        #print
        allsrc_tups = []
        everyclass_tups = []
        trainset_everyclass_tups = []
        #  Nice and kludgey.  Could do this in R if I knew it a bit better
        for i, srcid in enumerate(testdata_dict['srcid_list']):
            tups_list = zip(list(robjects.r("rf_clfr$test$votes[%d,]" % (i+1))),  possible_classes)
            tups_list.sort(reverse=True)
            for j in xrange(len(tups_list)):
                # This stores the prob ordered classifications, for top 3 classes, and seperately for all classes:
                if j < 3:
                    allsrc_tups.append((int(srcid), j, tups_list[j][0], tups_list[j][1]))
                everyclass_tups.append((int(srcid), j, tups_list[j][0], tups_list[j][1]))

        # # # This is just needed for filling the ASAS catalog tables:
        for i, srcid in enumerate(traindata_dict['srcid_list']):
            tups_list = zip(list(robjects.r("rf_applied_to_train$test$votes[%d,]" % (i+1))),  possible_classes)
            tups_list.sort(reverse=True)
            for j in xrange(len(tups_list)):
                trainset_everyclass_tups.append((int(srcid), j, tups_list[j][0], tups_list[j][1]))
        # # #

        #import pdb; pdb.set_trace()
        #print

        return {'al_probis_match':list(robjects.r('rf_clfr$test$votes[select,][,"match"]')),
                'al_probis_not':list(robjects.r('rf_clfr$test$votes[select,][,"not"]')),
                'al_deltaV':[robjects.globalenv['err.decr'][i-1] for i in list(robjects.globalenv['select'])],
                'al_srcid':[testdata_dict['srcid_list'][i-1] for i in list(robjects.globalenv['select'])],
            }
        """
        return {'actlearn_tups':actlearn_tups,
                'allsrc_tups':allsrc_tups,
                'everyclass_tups':everyclass_tups,
                'trainset_everyclass_tups':trainset_everyclass_tups,
                'py_obj':classifier_out,
                'r_name':'rf_clfr',
                'select':robjects.globalenv['select'],
                'select.pred':robjects.r("rf_clfr$test$predicted[select]"),
                'select.predprob':robjects.r("rf_clfr$test$votes[select,]"),
                'err.decr':robjects.globalenv['err.decr'],
                'all.pred':robjects.r("rf_clfr$test$predicted"),
                'all.predprob':robjects.r("rf_clfr$test$votes"),
                'possible_classes':possible_classes,
                'all_top_prob':robjects.r("apply(rf_clfr$test$votes,1,max)"),
                }
        """


    def main(self):
        """ Main method for initially prototyping this class.
        """
        train_fpath = '/home/dstarr/scratch/nomad_asas_acvs_classifier/train_chosen.arff'
        test_fpath  = '/home/dstarr/scratch/nomad_asas_acvs_classifier/notchosen_withclass_withsrcid.arff' #initialcase_withsrcid.arff'

        i_iter = 4
        n_test_to_sample=40000
        num_srcs_for_users=1000 #400

        random_seed = 1234

        ##### KLUDGE: initially we exclude all sources which have missing attributes
        #      - so we can do Active learning with imputation
        #      - generally the sources which have missing attributes are non-matches.
        train_lines = open(train_fpath).read().split('\n')
        train_lines2 = []
        for line in train_lines:
            if len(line) == 0:
                continue
            if '?' not in line:
                train_lines2.append(line)
        train_str = '\n'.join(train_lines2)

        test_lines = open(test_fpath).read().split('\n')
        test_lines2 = []
        for line in test_lines:
            # each source in this arff has '?' for a class, so we allow for that, but still skip missing attribs
            if line.count('?') <= 0:
                test_lines2.append(line)
        test_str = '\n'.join(test_lines2)
        #####

        # # # # # KLUDGE: we also give unique source_id names that represent NN rank and TUTOR srcid:
        test_lines2 = []
        test_str_split = test_str.split('\n')
        for i, line in enumerate(test_str_split):
            if len(line) == 0:
                new_line = line
            elif line[0] == '@':
                new_line = line
                if line.lower() == '@data':
                    test_lines2.append(new_line)
                    break
            test_lines2.append(new_line)
        i_header_end = i

        import random
        #for i, line in enumerate(random.sample(test_str_split[i_header_end + 1:], 1000)):
        for i, line in enumerate(random.sample(test_str_split[i_header_end + 1:], n_test_to_sample)):
            elems = line.split(',')
            try:
                srcid = "%d%0.2d" % (int(elems[0]), int(elems[2]))
            except:
                print 'EXCEPT:', elems, i, line
                import pdb; pdb.set_trace()
                print
            new_line = "%s,%s" % (srcid, ','.join(elems[1:]))
            test_lines2.append(new_line)
        test_str = '\n'.join(test_lines2)


        # # # # #
        
        traindata_dict = self.load_arff(train_str)
        testdata_dict = self.load_arff(test_str, skip_missingval_lines=False, fill_arff_rows=True)




        # TODO: ignore sources which have missing values, for now.
        #    -> TODO: we will train a general RF classifier which allows missing-values in test data


        # these are for all sources (train and test):

        ### The following lists contain a combination of sources:
        ###     - all training sources, and previous Active Learning trained sources
        ###     - sources which users recently attempted to classify for an
        ###         active learning iteration, including unsure/non-consensus ([False]) sources
        both_user_match_srcid_bool = [True] * len(traindata_dict['featname_longfeatval_dict']['dist'])# list of [True]
        actlearn_sources_freqsignifs = traindata_dict['featname_longfeatval_dict']['dist'] # list of cost metrics

        # ** TODO: need to add some ambiguoius sources?
        #       - ??? from the test_withsrcid.arff file?



        class_dict = self.actlearn_randomforest(traindata_dict=traindata_dict,
                                                     testdata_dict=testdata_dict,
                                                     mtry=5,
                                                     ntrees=500,
                                                     nodesize=5,
                                                     num_srcs_for_users=num_srcs_for_users,
                                                     random_seed=random_seed,
                                                     both_user_match_srcid_bool=both_user_match_srcid_bool,
                                                     actlearn_sources_freqsignifs=actlearn_sources_freqsignifs,
                                                     )
        actlearn_indexes = [testdata_dict['srcid_list'].index(i) for i in class_dict['al_srcid']]
        al_arffrows = [testdata_dict['arff_rows'][i] for i in actlearn_indexes]



        out_fpath = "/home/dstarr/scratch/nomad_asas_acvs_classifier/al_iter%d_ntest%d_nal%d.dat" % (i_iter, n_test_to_sample, num_srcs_for_users)
        out_fp = open(out_fpath, 'w')
        for i, arffrow in enumerate(al_arffrows):
            out_str =  "dV: %0.3f  M: %0.3f  NOT: %0.3f  %s\n" % (class_dict['al_deltaV'][i],
                                                                class_dict['al_probis_match'][i],
                                                                class_dict['al_probis_not'][i],
                                                                arffrow)
            out_fp.write(out_str)

        out_fp.close()
        import pdb; pdb.set_trace()
        print



if __name__ == '__main__':

    pars = { \
        # From get_colors_for_tutor_sources.py:
        'fpath_train_withsrcid':"/home/dstarr/scratch/nomad_asas_acvs_classifier/train_withsrcid.arff",
        'fpath_train_no_srcid':"/home/dstarr/scratch/nomad_asas_acvs_classifier/train_no_srcid.arff",
        'fpath_test_withsrcid':"/home/dstarr/scratch/nomad_asas_acvs_classifier/test_withsrcid.arff",
        'fpath_test_no_srcid':"/home/dstarr/scratch/nomad_asas_acvs_classifier/test_no_srcid.arff",
        }


    ncaa = Nomad_Colors_Assoc_AL(pars=pars)
    ncaa.main()
